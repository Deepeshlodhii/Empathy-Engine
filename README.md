# üéôÔ∏è The Empathy Engine ‚Äì Emotion-Aware Text-to-Speech System

The Empathy Engine is an AI-powered service that converts plain text into emotionally expressive speech.  
Unlike traditional monotonic TTS systems, this project detects the emotion in the input text and dynamically modulates vocal characteristics such as pitch, speaking rate, volume, and prosody to produce more human-like and emotionally resonant audio output.

This project demonstrates how sentiment analysis and modern neural TTS systems can be combined to build next-generation voice assistants for sales, customer support, and conversational AI.

---

## üöÄ Features

- Accepts text input via CLI or Web UI
- Emotion detection (Positive / Negative / Neutral)
- Emotion intensity scaling
- Dynamic voice modulation:
  - Pitch
  - Speaking rate
  - Volume / stability
  - Prosody & speaking style
- High-quality neural speech synthesis (ElevenLabs or Google TTS)
- Generates downloadable `.wav` audio output
- Flask-based web demo interface

---

## üß† System Architecture

```

Text Input
‚îÇ
‚ñº
Emotion Detection (VADER)
‚îÇ
‚ñº
Emotion + Intensity Mapping Logic
‚îÇ
‚ñº
TTS Engine (ElevenLabs / Google Cloud)
‚îÇ
‚ñº
Emotional Audio Output (.wav)

```

---

## üõ†Ô∏è Tech Stack

- Python 3.9+
- NLTK (VADER Sentiment Analyzer)
- Flask (Web UI)
- ElevenLabs API / Google Cloud Text-to-Speech
- Requests

---

## üìÇ Project Structure

```

empathy-engine/
‚îÇ
‚îú‚îÄ‚îÄ app.py                    # CLI application
‚îú‚îÄ‚îÄ web_app.py                # Flask web interface
‚îú‚îÄ‚îÄ emotion.py                # Emotion detection logic
‚îú‚îÄ‚îÄ tts_engine_elevenlabs.py  # Emotional TTS engine
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îî‚îÄ‚îÄ speech.wav
‚îî‚îÄ‚îÄ README.md

````

---

## ‚öôÔ∏è Setup Instructions

### 1. Clone Repository

```bash
git clone (https://github.com/Deepeshlodhii/Empathy-Engine)
cd empathy-engine
````

---

### 2. Create Virtual Environment

```bash
python -m venv venv
```

Activate:

**Windows**

```bash
venv\Scripts\activate
```

**Mac/Linux**

```bash
source venv/bin/activate
```

---

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4. Download NLTK Sentiment Model

Run once:

```bash
python
```

```python
import nltk
nltk.download('vader_lexicon')
exit()
```

---

### 5. Configure TTS API

#### Option A ‚Äì ElevenLabs

1. Create account: [https://elevenlabs.io](https://elevenlabs.io)
2. Generate API key (enable "Text to Speech" permission)
3. Paste API key into:

```python
API_KEY = "your_api_key_here"
```

inside `tts_engine_elevenlabs.py`

(Optional: use `.env` for security)

---

#### Option B ‚Äì Google Cloud TTS (alternative)

Follow Google Cloud TTS setup if ElevenLabs free tier is blocked.

---

## ‚ñ∂Ô∏è Running the Application

---

### CLI Version

```bash
python app.py
```

Enter any text when prompted.

---

### Web Interface Version

```bash
python web_app.py
```

Open browser:

```
http://127.0.0.1:5000
```

---

## üß™ Example Inputs

**Positive**

> This is the best day of my life! Everything finally worked out!

**Negative**

> I am extremely disappointed and frustrated with this service.

**Neutral**

> The meeting is scheduled for tomorrow at 10 AM.

---

## üéõÔ∏è Design Choices & Emotion-to-Voice Mapping

### 1. Emotion Detection

We use **VADER Sentiment Analysis (NLTK)** to compute a compound sentiment score:

| Score Range | Emotion  |
| ----------- | -------- |
| ‚â• 0.4       | Positive |
| ‚â§ -0.4      | Negative |
| Otherwise   | Neutral  |

The absolute value of the compound score is used as **emotion intensity**.

---

### 2. Voice Parameter Mapping Logic

Each detected emotion maps to a specific vocal configuration:

| Emotion  | Pitch  | Rate   | Volume / Stability | Speaking Style |
| -------- | ------ | ------ | ------------------ | -------------- |
| Positive | High   | Fast   | High energy        | Expressive     |
| Negative | Low    | Slow   | Softer             | Calm / serious |
| Neutral  | Normal | Normal | Balanced           | Neutral        |

---

### 3. Intensity Scaling

Emotion intensity dynamically controls how strong the modulation is:

Example:

| Text                           | Effect                     |
| ------------------------------ | -------------------------- |
| "This is good."                | Slight pitch increase      |
| "This is the best day ever!!!" | Strong pitch + faster rate |

---

### 4. TTS Engine Choice

We selected **neural TTS (ElevenLabs / Google Cloud)** because:

* Supports pitch control
* Supports prosody
* Produces human-like voices
* Allows programmatic control
* Works with SSML

---

## üìå Assignment Requirements Checklist

| Requirement                     | Status |
| ------------------------------- | ------ |
| Text Input                      | ‚úÖ      |
| Emotion Detection (‚â• 3 classes) | ‚úÖ      |
| Rate modulation                 | ‚úÖ      |
| Pitch modulation                | ‚úÖ      |
| Volume modulation               | ‚úÖ      |
| Emotion-to-voice mapping        | ‚úÖ      |
| Audio output (.wav)             | ‚úÖ      |
| Web interface                   | ‚úÖ      |
| Intensity scaling               | ‚úÖ      |

---

## üå± Future Improvements

* Transformer-based emotion classifier (6+ emotions)
* SSML fine-grained emphasis control
* Multiple voice profiles
* Language detection
* Real-time streaming audio
* Cloud deployment (Render / Docker)

---

## üë®‚Äçüíª Author

**Deepesh Lodhi**
AI & Data Science Enthusiast
IIT Delhi



